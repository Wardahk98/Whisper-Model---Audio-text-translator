# Whisper-Model---Audio-text-translator
The project transcribes diverse audio files and subsequently translates the transcribed text into a user-defined language.
The project employs the Whisper model, integrated with PyTorch, to facilitate seamless transcription of diverse audio files. The transcribed text is subsequently translated into a user-defined language, adding a multilingual dimension to the application. Leveraging GoogleTrans for translation and iso639 for language code management, the project ensures efficient language conversion, making it a versatile tool for audio content comprehension across linguistic boundaries. Prerequisites include PyTorch installation, Chocolatey for package management, and FFmpeg installation through Chocolatey. The script allows users to specify audio files, target languages, and effortlessly obtain transcriptions translated into their preferred languages.
